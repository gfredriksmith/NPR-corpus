 The world of social science got a rude awakening a few years ago when researchers concluded that many of the studies in this area appear to have deep flaws. Some of those same researchers now report that it is a problem even for the most prestigious scientific journals. But their study also finds that some scientists are surprisingly good at anticipating which studies are likely to stand the test of time. NPR's Richard Harris reports.  Science is a process of exploring the unknown. So Brian Nosek at the Center for Open Science and the University of Virginia says we should not expect every result to be repeatable in someone else's lab. The challenge is separating the good from the bad.  A substantial portion of the literature is reproducible. We are getting evidence that someone can independently replicate. And there is a surprising number that fail to replicate.  Nosek wanted to see how that plays out in the journals where scientists often take their flashiest and most provocative findings Science and Nature. Nosek and his far-flung colleagues now report that of the 21 social science papers published in those journals over a recent five-year span 13 checked out and eight apparently did not. One of the eight studies that failed this test came from the lab of Will Gervais. He and a colleague at the University of British Columbia ran a series of experiments to see whether people who are more analytical are less likely to hold religious beliefs. In one test undergraduates looked at pictures of statues.  So half of our participants looked at a picture of the sculpture The Thinker where you know here's this guy engaged in deep reflective thought. And in our control condition they would look at the famous statue of a guy throwing a discus.  People who saw The Thinker expressed more religious disbelief. But Gervais now on the faculty of the University of Kentucky recognizes that his experiment was really quite weak.  Our study in hindsight was outright silly.  But what interested him most in the new study involved an interesting twist. Several hundred social scientists were asked in advance to predict which studies would pan out and which ones would not.  They are taking bets with each other against us.  Anna Dreber is at the Stockholm School of Economics and co-author of the new analysis which is published in Nature Human Behavior. She says those forecasts were spot on.  So these researchers were very good at predicting which studies would replicate. So I think that is great news for science.  Dreber says if you can get panels of experts to weigh in on exciting new results the field might be able to spend less time chasing faulty conclusions known as false positives.  A false positive result could make other researchers and the original researcher spend lots of time and energy and money on results that turnout to not hold. And that is kind of wasteful for resources and inefficient. So the sooner we find out that a result does not hold the better.  This is a very intriguing idea but Jonathan Kimmelman at McGill University says it may be limited to a group of scientists with particular skills. When he is asked medical researchers to make predictions about studies the forecasts have generally flopped.  That is probably not a skill that is widespread in medicine.  Better than detecting problems in already completed research scientists like Will Gervais are thinking hard about the incentives that encourage them to do weak small studies in the first place.  The way to get ahead and get a job and get tenure is by publishing lots and lots of papers and it is hard to do that if you are able to run fewer studies. But in the end I think that is the better way to go - is to kind of slow down our science and be more rigorous up front.  He says that is the approach he is taking. And he sees it as part of a broader cultural change in social science that is aiming to make the field more robust. Richard Harris NPR News. 