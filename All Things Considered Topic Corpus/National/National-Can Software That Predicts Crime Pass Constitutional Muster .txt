 Some police departments are trying to predict the future. They are using software that lays out statistics from the past to project where crime is moving. Police in Los Angeles say it has worked well in predicting property crimes. Now Seattle is about to expand it to gun violence. But as we hear from NPR's Martin Kaste police are hesitant about relying too much on computers.  This all started as a research project. An anthropologist at UCLA Jeff Brantingham wanted to see if computers could model future crime the same way they model earthquake aftershocks. Turns out they can. DR.  It predicts sort of twice as much crime as any other existing system even going head-to-head with a crime analyst.  Older systems like the famous CompStat in New York show where crime has been. This looks forward.  The model will actually predict other locations that effectively say even though there was a crime somewhere else in your environment the risk is still greatest in this location today in the next 10 hours or the next 12 hours.  Brantingham and his colleagues are now selling this predictive system to police departments. They call their product PredPol. And at this point you are probably already thinking about the sci-fi movie Minority Report. But this is different. There are no psychics sleeping in bathtubs for one. But more to the point this is not about predicting the who of future crime just the where.  These red boxes are predictions of where the next crimes are likely to occur.  Police Sergeant Christi Robbin pinches and zooms on a map of Seattle. Earlier this year the city started using PredPol to predict property crimes. Now it is expanding the system to predict gun violence too the first place to do so. At the start of every shift patrol cops are assigned to the boxes on the map.  So we are asking that they spend the time in that 500-by-500-square-foot box doing whatever proactive work they can to prevent that crime.  ...next block down and just - so this is the spot to park. We are going to park here.  Officer Philip Monzon has just pulled up inside his box. Today it is a city block near the Seattle waterfront.  They want visibility. They want contacts with businesses as are appropriate and anybody who is wandering through the area. So here we go.  This area has a lot of parking lots and PredPol's forecast includes car thefts. As Monzon passes a green Honda he pauses. The guy inside seems to be ducking under the dashboard.  I just want to make sure if he has a key or if he is going to pull out anytime soon.  The car starts the guy probably does have the key. But why did not Officer Monzon challenge him just in case?  I do not really have enough - I am not going to just single out one guy in a Honda.  And here's where this gets tricky. The courts say police need reasonable suspicion in order to stop somebody. That suspicion can come from a lot of things even someone's furtive movements as the police like to say. But can it come from the fact that someone is occupying an imaginary red box drawn by a computer?  No no. I do not know. I would not make a stop solely on that.  That is probably the right answer says Andrew Guthrie Ferguson. He is a law professor at the University of the District of Columbia and he is taken a special interest in the constitutional implications of PredPol. He says the departments using it have told police not to use it as a basis for stops. But he wonders how long that can last.  The idea that you would not use something that is actually part of the officer's suspicion and not put that in may come to a head when that officer is testifying and either is going to have to omit a fact that really was the reason he stopped or she stopped the suspect or is something that they will then admit on the stand and then the issue will be raised for the court to address.  And it may be that PredPol is a constitutional basis for stopping someone. Some might see it as more objective than a cop's judgment less prone to racism or other kinds of profiling. Ferguson says that is possible but we need to be careful.  I think most people are going to defer to the black box which means we need to focus on what is going into that black box how accurate it is and what transparency and accountability measures we add to it.  In other words even though computers are not biased the stats feeding them might be. And he says if we are going to follow an algorithm we should at least be willing to check the math. Martin Kaste NPR News Seattle.   This is ALL THINGS CONSIDERED from NPR News. 