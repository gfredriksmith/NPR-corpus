 Here's a riddle for the digital age. Why did the scientist create a robot that hurts humans - answers on this week's All Tech Considered.   The science fiction author Isaac Asimov famously created the Laws of Robotics. The first one is that a robot should never harm a human being. But one artist-slash-roboticists has inverted that law to provoke discussion about a future where robots may have the power to make choices about human life. NPR's Laura Sydell reports.  MIT-trained roboticists and artist Alexander Reben admits his robot has no practical purpose. It is designed to prick human fingers.  It hurts a person obviously in the most minimal way with this needle. And it makes a decision in a way that me as the creator cannot predict. So the idea is that when you put yourself near this robot it will decide whether or not to hurt and injure you. There is no human in the loop of this decision.  It is not a very elaborate robot just a robotic arm on a platform. It is smaller than a human arm but shaped a little like the arm of one of those excavators they use for construction. Instead of a shovel on the end there is a pin.  And you put your hand near the robot. And it senses you. Then it goes through an algorithm to decide whether or not it is then going to put the needle through your finger.  I dared to put my finger beneath the arm. It swings past me several times and then - oh. The waiting is the hardest part. And in case you were wondering each needle is sterilized. Reben says the point of this robotic sculpture is to get people to think about a world in which programmed machines like self-driving cars make the decision to hurt a human. For example what would happen if a self-driving vehicle must decide whether to drive you into a tree or hit a group of pedestrians?  The answer might even be that well these machines are going to make decisions so much better than us and it is not going to be a problem. They are going to be so much more ethical than a human could ever be.  But what about the people who actually get into those cars?  If you get into a car do you have the choice to not be ethical ?  And people want to have that choice. A recent poll by MIT Media Lab found that half of the people in the survey would buy a driverless car that put the highest protection on passenger safety but only 19 percent said they would buy a car program to save the most lives. The popular science fiction author Isaac Asimov inspired Reben's work. Asimov even made up laws for robots. One of his stories I Robot was made into a film starring Will Smith. Smith plays an emotional cop chasing a killer robot. Here's a scene where he is speaking with a roboticist played by Bridget Moynahan.    A robot cannot harm a human being the first robotics.   Yeah I know. I have seen your commercials. But does not the second law state that a robot has to obey any order given by a human being? What if it was given an order to kill?  Or hurt someone. Asimov's laws for robots are often cited by scientists in the field as a kind of inspiration and talking point as we move towards a world of increasingly sophisticated machines. And Asimov's stories often show how no matter how hard humans try to program robots not to harm people complicated situations arise.  The ability to even program these fictional laws into a robot is very difficult. And what they actually mean when you really try to analyze them is quite gray. It is a quite fuzzy area.  For example should a programmer design a robot that will never hurt a person even if doing that would save another life? Reben says the point of making his robot is to put something in the world now before machines have those powers in say self-driving cars.  If you see a video of a robot making someone bleed all of a sudden it taps into this viral nature of things. And now you really have to confront it. It is something different.  And you can go online and watch Reben's robot and ponder the power that our future overlords will have over us someday. Laura Sydell NPR News. 