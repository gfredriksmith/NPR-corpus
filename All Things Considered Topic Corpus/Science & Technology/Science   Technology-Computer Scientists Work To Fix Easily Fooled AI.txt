 Researchers are discovering something unnerving about artificial intelligence. It is easy to fool - so easy in fact there is a whole field of study known as adversarial AI that actually aims to make artificial intelligence a little smarter. As part of an NPR special series on the technologies that watch us Dina Temple-Raston has more.  Artificial intelligence is all about showing a machine millions of examples so it can learn to recognize things in the real world. And there is a pretty famous experiment about how easily this can go wrong. It was conducted by a team of researchers led by UC Berkeley professor Dawn Song.  Let me start playing the video.  She and her colleagues made a video that showed how they fooled AI and in this case fooled a system while it was driving a car. The video is less than a minute long. And it does not have any sound but it rocked the AI community.  So in the video you will see two frames side by side.  Think split screen. All you need to know now is that each split screen is subtitled so you could see how the AI and specifically a subset of AI called image classification is making decisions inside the autonomous car.  You see the prediction given by the image classification system to try to predict what the traffic sign is.  So sort of like the car starting to think a sign is coming I am going to have to make a decision.  Right.  So Song and her team had the AI system read two stop signs. One was a perfectly normal stop sign. The other was manipulated. Song had put one sticker below the S and another above the O in stop. And as the car gets closer to it the subtitles are describing the AI's decision-making process. It reads the regular stop sign just fine and is telling the car to prepare to stop. But the one with the stickers it thinks the sign reads speed limit 45 miles an hour which would allow the car if this was not an experiment to blow right through the intersection. Two carefully placed stickers was all it took to make a self-driving car run a stop sign. So you were expecting it to misread the sign. And then it did and you were happy about that.  It is surprising still given how well it works.  It works so well that people who are developing driverless cars tapped the brakes. Now to be fair Song's team did not just randomly throw some stickers onto a sign. They knew exactly how the AI's image classification system worked. They knew which pixels of the sign to manipulate to fool it which got the attention of people over at fense Advanced Research Projects Agency. And to understand why the military's top research arm was so concerned I went to DARPA headquarters to meet with Hava Siegelmann. I am Dina Temple-Raston.  Hey Dina. I am Hava.  Thank you for making the time. She is the director of something called the GARD project. GARD stands for Guaranteeing AI Robustness against Deception. And just like it sounds it is looking for ways to make artificial intelligence more hack-proof. The way AI makes decisions is a bit of a black box. But Siegelmann says if you understand what the system has chosen to focus on you can fool it. And if you are  less worried about a stop sign than say putting a sticker on a tank.  And because that sticker that has particular color we think that this tank is actually an ambulance. And immediately we open the gates to let the ambulance go in.  The reason to study all of this is not to scare us about AI although it does that too. Researchers want to understand the limits of AI so they can fix it kind of like old-fashioned hackers who used to call up software companies and let them know about flaws in their coding so they could send out patches. Dawn Song says the bottom line is machine learning and AI are not as powerful as people think they are.  We do really need new and more breakthroughs before we can really get there.  So would you ride in a driverless car?  Not today . I mean I will enjoy having a test drive but ...  And by the way Dawn Song's special stop sign with the stickers is not fooling driverless cars anymore. It is now hanging in the Science Museum in London. It is part of an exhibit about our driverless future. Dina Temple-Raston NPR News Washington. 