 Facebook groups are ripe targets for bad actors for people who want to spread misleading wrong or dangerous information. So warns Nina Jankowicz. She is the disinformation fellow at the Wilson Center. And in a recent opinion column in WIRED magazine she and a co-author write that the company's so-called pivot to privacy Facebook's promise to protect sensitive user information did little to combat the spread of misinformation. Instead Facebook encouraged users to join its groups which are private pages for users with similar interests. We want to note here that Facebook is among NPR's recent financial supporters. Nina Jankowicz is here with us now. Welcome.  Thanks for having me Sarah.  So make the case. Why as you write are Facebook groups destroying America?  Well the most important thing to understand is that disinformation runs on emotion and groups are highly emotional spaces. Over time the moderators of groups use the community that they build there to create a sense of trust. And in many cases people use it for a lot of great things. But in some cases these are really polarizing environments where not only are people getting content that is really indoctrinating there - we are seeing some white supremacist content there we are seeing the Obamagate conspiracy spreading through groups. So you join one group then you will be suggested to join another group. So it is a really difficult problem to solve because at the core of this is Facebook's business model. It wants you to spend more time on the platform more engagement. And if that engagement is serving you more divisive content it is going to keep doing that.  Remind us if you would what is the difference between these Facebook groups and the way the rest of Facebook works? And what makes them so susceptible as you say to disinformation?  So after the 2016 election Facebook really wanted to make the platform a little bit more like your digital living room and not the digital public square. It surfaced more content from friends and family and groups were a big part of that strategy. Rather than seeing content from pages which you know media outlets brands celebrities have it was surfacing more of that friends and family content. It is a real problem though. Basically these are spaces that are not - they do not have the same amount of oversight as other spaces. They are moderated by group moderators. And Facebook does not look at them but they can also be private and secret which means that bad actors can target people who are going to be most vulnerable.  You write about the dangers of Facebook groups. Now not everybody's on Facebook. Not everybody's in groups. There is a whole universe of social media out there where false and inflammatory content is also spreading. Why focus on this?  The reason that my co-author and I decided to focus on groups is because it has been the primary vector of disinformation on Facebook for the past several years. And I think it is kind of a sleeping giant. People do not realize that because of the community and the trust that is endemic to groups that they might be being played. And I think it is really important to raise awareness about that especially as we head into the election. We need to have our guards up right now.  So what changes does Facebook need to make?  We think it is really important that Facebook show how groups are connected because often one group moderator will control several groups that are sharing similar divisive or straight-up disinformation content. And users deserve to know that. And after a certain point groups are not really private spaces anymore if they have tens or hundreds of thousands of members. So we are suggesting that Facebook not allow groups to be private or secret over a certain threshold say 5000 members. So I think the bottom line is more transparency. I think the most important thing is to arm users with information so that they can navigate this information flow during these very confusing times.  That is Nina Jankowicz with the Wilson Center. Thanks so much for your time.  Thanks for having me.  