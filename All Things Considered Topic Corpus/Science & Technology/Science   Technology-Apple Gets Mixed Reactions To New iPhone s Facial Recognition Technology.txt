 When Apple announced the new iPhone can use facial recognition technology to unlock the device the response may not have been what Apple had hoped for. The feature immediately raised privacy and security concerns. To hear more about that we are joined now by Clare Garvie. She is an associate at the Center on Privacy and Technology at Georgetown Law Center and co-author of  Unregulated Police Face Recognition In America. She is with us now in our studios in Washington D.C. Clare Garvie thanks so much for joining us.  Thank you for having me on.  So lay out the privacy and security concerns for us. It sounds - I mean the technology first if you think about it sounds really cool. So what is the concern?  That is right. The technology is both convenient and it is really cool. And frankly I do not see too many privacy and security concerns with the way Apple has chosen to deploy face recognition. What I am far more concerned about is as face recognition becomes normalized as it becomes something that we use on an hour to hour basis to send an animated emoji to check the weather to send a text what is going to happen is we get very comfortable with it. And we forget that it is used by any number of actors in ways we may not know about that is both less accurate and more privacy concerning than the way that Apple has chosen to use it.  Well give us the worst-case scenario. Give us some scenarios that would cause concern.  So right now happening in Russia face recognition has been used to scan anti-government or anti-corruption protests identify and then publicly name the people at those anti-government protests. What this means is these people will be subject to intimidation if not arrest for their political beliefs. Now before someone says well wait that is Russia. Why should we in the U.S. care about that? The fact remains in the U.S. it is very much a rules-free zone when it comes to face recognition. Law enforcement across the country use this technology in various ways without any laws governing its use. Evidence suggests that it was used on protesters after the death of Freddie Gray in police custody. It looks like face recognition was used on social media posts that protesters were posting from demonstration sites. So the law enforcement agents on the ground could in almost real time get the identities the names of the people at those protests. We are a country where we do not necessarily need to show our papers every time we walk down the street. If law enforcement demands our identity we do not necessarily need to give it. And yet our faces - now something we have to present in public - have now done that work for us.  Sounds to me that your concern is not so much this particular technology but that - what? - that it opens the door to a broader use? Is that really Apple's fault or responsibility?  I do not believe it is Apple's fault. And I think Apple has thought very very carefully about a number of the security concerns. They have chosen to store the face template if you will locally on the phone which means that it is a lot more secure against being hacked and being stolen. The real concern is that as face recognition becomes normalized we may stop worrying about the very real concerns that we should be worrying about as we increasingly are subjected to face recognition that we cannot opt out of.  That is Clare Garvie. She is an associate at the Center on Privacy and Technology at Georgetown University's Law Center. She was kind enough to join us at our studios in Washington D.C. Clare Garvie thanks so much for speaking with us.  Thanks for having me on. 