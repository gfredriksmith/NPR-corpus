   All right. Hello? Hello? Hello? Hello? Hello? Hello? I can hear you. They cannot hear me.   We can hear you. We can hear you.   But you cannot.   But what we can also hear is us twice -- us twice.   Hey I am Jad Abumrad.   I am Robert Krulwich.   This is Radiolab. And today ...   Oops. Oops. You do not -- you do not hear -- you do not hear us ...   We have a story about how the echoes of you can go out into the world and come back and bite you and all of us really in the butt.   Oh wait. Maybe we are fine now.   Is my echo gone?   Yes.   Okay. Okay we are good.   We are good?   And it comes to us from our producer Simon Adler.   Yeah Nick. Hello!   I am sorry.   Okay so this is Nick Bilton.   My name is Nick Bilton. I am a special correspondent for Vanity Fair.   And his beat you could say is trying to predict the future of technology.   To look into the future and to this kind of crystal ball and try to predict what the next 5 10 15 years would look like for the media industry.   Do you have a good batting record? Like did you -- did you call some big ones?   Oh yeah. You know phones in our pockets that would be like super computers that social media would drive news not newspapers and so on and things like that. So it is been pretty good.   I reached out to you because I came across this article that you wrote an article that sent shivers down my spine. And I am not one to typically be given shivers by articles. So I guess how did you stumble into all of this? And where does this start for you?   So I was sitting around with some friends in my living room and a friend of mine mentioned Oh did you see this thing that Adobe put out recently?     And that conversation led Nick to a video. A video online of the Adobe Max 2016 conference. There are tons and tons of people in the audience.     And up in front of them it looks like the stage of a Apple product launch but sort of beach-themed?   Why beach?   I have absolutely no idea.     There are two hosts that are sitting in these like lifeguard chairs.     Comedian Jordan Peele.   Jordan Peele as in Key  Peele Jordan Peele?   Yes. And then the other host is this woman Kim Chambers who is a marathon swimmer and an Adobe employee. And then ...     On walks ...     Zeyu Jin.     Young guy. Glasses.     And he says Adobe is known for Photoshop we are known for editing photos and doing magical things visually.     Pulls up a screen on a Mac computer.     Keegan-Michael Key had been nominated for an Emmy and he and Jordan Peele were talking about it.       Not a bad joke.     In other words what if Keegan-Michael Key was feeling like that was a little bit rough on my wife that was a little bit mean you know maybe he wanted to go and rewrite history and say that he kissed his wife before the dogs.     So Zeyu clicks a button and the program automatically generates a transcript of the audio and projects it up on the screen behind him. You know just text of what Keegan-Michael Key said.     And then ...     He just highlights the word wife and pastes it over in front of dogs.     Clicks play.       Oh so he was able to move the -- edit the audio by moving the text around in the text box.   Yes exactly.   Okay. Well that is kind of cool.   Kind of impressive.     But then ...     Wait Wait what?   Just hang on. Just hang on.         He goes back into that little word box.         So he types it out J-O-R-D-A-N. And just to be clear Keegan-Michael Key did not say Jordan anywhere in this clip.         Wait he just typed in a word that the guy never said and it made the guy say the word that he never said as if he actually said it.   Exactly.       Jordan jumps out of his lifeguard chair starts sort of stomping around the stage.       He deletes the words my dogs and he types three times.           All right wait a sec. You are saying that Keegan-Michael Key never said ever said Jordan never said three never said times never said any of those words and somehow just from the typing in of it the guy is now saying them and we are hearing them in his voice. That is what just happened?   Yep. That is exactly what the demo claims.   It is essentially Photoshop for audio.   Nick Bilton again.   You could take as little as 20 minutes of someone's voice type the words and it creates in that voice that sentence.   With just 20 minutes of the guy talking.   Yes.   But how? How in heaven do you do this?   And so we are here at Adobe. What exactly do you do here?   Sure. I am the product manager for audio.   This is Durin Gleaves. I flew out to Seattle and tracked him down to ask him exactly that question.   So essentially what it does is it does an analysis of the speech and it creates models. And it basically ...   And he explained to me that this program which they call VoCo by the way what it does is it takes 20 minutes or actually 40 if you want the best results of you talking and it figures out all of the phonetics of your speech all of the sounds that you make.   Finds each little block of sound and speech that is in the recordings.   Chops them all up. And then when you go and type things in ...   It will recombine those into that new word.   But what if it encounters a sound that I have never made?   Well the theory is in 40 minutes of speech which is the amount they recommend you feed in you are gonna probably say just about every sound.   Really?   In the English language.   So if -- really? So like phonetically I go -- I run through the gamut in 40 minutes?   Yes.   Wow!   Well and like what would you or what are you hoping people would use a product like VoCo for?   So for the video production tools and for what Audition is used for a lot is dialogue editing.   The whole idea Durin said is to help people that work in movies and TV.   A lot of our customers record great audio on set. The actors and the dialogues and everything. And when they come back if sometimes there is a mistake or they make a change.   Like the actor on set said shoe but what he was pointing at was obviously a boot.   And right now there is -- they do what is called ADR. They will bring the actor in they will re-record some lines and they will try and drop that into the video.   But you are not using the same microphones you are not in the same location the actor might be sick that day so his voice sounds different.   And things -- a lot of times you can really hear that stand out in productions if they do not get it just right.   But with VoCo you just delete the word shoe type in boot and boom! There it is.   Using the same source media and the same characteristics and have it just sound seamless and natural.   And so it -- it is going to be a sort of -- the hope is that it will make the lives of professional post-production editors easier the world over.   That is our hope right now yeah.   But that is not exactly ...   It is -- I mean it is ...   ... what Nick Bilton thought when he saw this video.   It could be Donald Trump's voice or Vladimir Putin. So I saw that and I thought Wow if -- imagine if audio clips start getting shared around the internet as fake news of a fake conversation between you know Vladimir Putin and Paul Manafort about trying to get Trump into the White House or something like that.   Right.   And I was like Whoa this is -- this is scary stuff.   But we are just getting started. In the words of John Raymond Arnold played by Samuel L. Jackson in the movie Jurassic Park in his own voice.     Things are about to get a lot crazier.     So forget voices for a second because now ...   1 2 3 4 5. 1 2 3 4 5.   Its face time.   All right we are at the Paul G. Allen Center at the University of Washington in Seattle.   So I left Adobe and went across town to talk to the head of the Grail Lab.   Hello.   Hello Ira?   Yeah.   Simon. Very nice to meet you.   Nice to meet you.   Dr. Ira Kemelmacher-Shlizerman.   So I am a professor in the computer science department at the University of Washington and also work at Facebook.   Can I just have you come a little closer?   Okay just to back up for a second. When Nick first saw the VoCo demonstration he started to wonder okay like how could this be used down the road?   My original thesis was oh well maybe what will happen is that you will be able to create 3D actors just like you did in Star Wars.   Then join it with the VoCo stuff to ...   Create a fake Hillary Clinton and you know Donald Trump having a conversation or making out or whatever it is you want to do.   And that led him to investigate the type of work that Ira does.   So I have been using these terms like facial reenactment and facial manipulation. Are those -- are those the right words? And then what the hell do these words mean?   Yeah. So I mean it is all -- it is all a way of animating faces. And it started from the movies right?     Think like the aptly-named movie Avatar. Or ....       Going a little further back.     Toy Story. And to make the characters come alive what you need is the expressions of the actors playing them.   This is a movie space. It means that you will bring a person to a studio.   Then you cover their face with these sticky sensory marker things.   And then you will spend hours hours hours capturing the person's little dynamics.   Like smiles.   Open mouth.   Teeth.   Closed mouth.   No teeth.   Sad.   Surprised. Disturbed.   Things like that.   Angry. Bloated. Frustrated.   Yeah.   And from that they create a virtual character capable of emoting all those expressions. And to make that character believable the animators sometimes have to model a bone structure and muscles. And as you can imagine this can get very very expensive. And so what people like Ira started to wonder was like can this be done on a budget? So she and others in the field started feeding videos of faces into computers and trained those computers to break down the face into a series of points.   Our models are about 250 by 250.   That is 62500 points on one human face.   And once we know that right we can track the points.   So once you can track how my face moves through a video clip by these 250 by 250 points what can you then do with that information?   Well I can apply the points on the face on a different model of a different person.   Now this is -- this is where things get quite strange because instead of being able to map all of your facial movements onto a computer-generated virtual character or person what Ira and others in this field of facial reenactment have figured out how to do is to map your facial movements onto a real person. A pre-recorded real person.   What? What does that even mean?   Yeah how does that work?   Well the best example of this is this piece of software that Nick showed us.   This software that I found from these university students.   Called Face2Face.     There is a video demo of this and when you open it up this very monotone voice comes in saying ...     And you are like what the heck is this? And this screen pops up.     On the right you have got this heavyset man. Goatee spiked hair.     He is arching his eyebrows he is pursing his lips he is opening his mouth widely.   Sort of like if you are making funny faces for a two-year-old kind of thing?   Yeah. And then ...     On the left you have got this Dell computer screen displaying a CNN clip of George Bush. This is a real clip of Bush back from 2013. And his face is there looking right at the camera occupies most of that screen.     And what you start to notice is when the man with the goatee smiles George Bush in the CNN clip also smiles. And when the man raises his eyebrows George Bush raises his eyebrows. And you realize this man is controlling George Bush's face.   Wait so this is a guy in -- in the present controlling a past George Bush? A real George Bush from an old video clip?   Yeah.   Okay. I pulled up a video for you here.   Okay cool.   And a little while back when we were just learning about this we happened to have our friend Andrew Marantz who writes for the New Yorker in the studio.   So that is George Bush's face.   Mm-hmm.   What? Oh God! Oh God! That is terrifying. His -- okay. So yeah I cannot stop watching George Bush's face. Oh they are doing it with Putin now. Holy God! So I just have a guy just sort of going  and then that is what Putin is doing.   Yeah.   Uh-oh. Now it is Trump.   You know I mean those videos online had my mouth agape.   Again Nick Bilton.   This is -- this is a form of puppetry where ...   Your face is the -- is the puppeteer. And the only thing is is that George W. Bush is the puppet.   So I sit in front of a camera I smile and the business is taken care of?   That is real time. This is not like you have to render some software on your computer. It is literally you download a clip or you take a clip from cable news and you turn on your webcam and however long it takes you to do it you are done. It is the same as just shooting a video on your phone.   What is this for?   So what are the applications of this?   I want to be able to help -- help develop tele-presence.   This is Ira again.   So ...   Tele-presence?   Tele-presence yeah.   What does that mean?   So for example so my mom lives in Israel and I am here and would not it be cool if I could have some -- it is kind of crazy right? But if I could have some kind of hologram of her sitting on my couch here and we can have a conversation.   And going one step further one of Ira's colleagues a guy by the name of Steve Seitz.   I am a professor at the University of Washington and I also work part-time at Google.   He told me that they see this technology as like a building block that could one day be used to essentially virtually bring someone back from the dead.   I just think this technology combined with virtual reality and other innovations could help me you know just be there in the room with Albert Einstein or Carl Sagan. You know that is sort of the motivation.   That is what they want to do?   That is the motivation?   Talk to ghosts?   Well for them. Yes. And when I was talking to some folks who work in commercials they are developing their own version of this. And the idea is that they are gonna make a million or a billion dollars off of this because say you bring I do not know Jennifer Aniston in to film some makeup commercial. And in the makeup commercial in English she says So come and buy this product. This is the best sort of whatever product around. Right now you have got China which is a booming market. You maybe want to market things to China and you would really like to be able to use Jennifer Aniston. Problem is Jennifer Aniston does not speak Mandarin. So either you use the same audio clip and you have someone come in and speak Mandarin over her and the lips do not line up. Or you have to hire a Mandarin-speaking actor to come in and do the part of Jennifer Aniston. With this technology all you have to do is record Jennifer Aniston once. You can hire a Mandarin speaker and the Mandarin speaker's voice will be coming out of Jennifer Aniston's mouth as if she had said it in front of the camera.   Her lips would be moving as if she were a perfect Mandarin speaker?   Exactly. Exactly.   Wow!   I think that part of it is actually incredible.   That is -- that is amazing.   Yeah.   Oh my God. I am amazed and completely frightened by what you are telling me.   And that is the whole point of what Nick was writing about that that gave me shivers. That someday if you join the video manipulation with the VoCo voice manipulation ...   You are -- you are the ultimate puppeteer. You can create anyone talking about anything that you want.   In their own voice.   And having any kind of emotion around it.   And you would have it right there for everyone to see in video.   And all you need to do is take that and put it on Twitter or Facebook. And if it is shocking enough minutes later it is everywhere.   Like the timing of you guys making this thing and then this explosion of fake news. Like how do you guys think about -- about how it could be used for nefarious purposes?   Yeah it is a good question.   Again Ira Kemelmacher-Shlizerman.   I feel like when every technology is developed then there is this danger of with our technology you -- you can create fake videos and so on. I do not want to call it fake videos but like to create video from audio right?   But they are fake videos.   Yeah yeah. But the way that I think about it is that like scientists are doing their job and showing -- like inventing the technology and showing it off and then we all need to like think about the next steps obviously. I mean people should work on that and the answer is not clear. Maybe it is in education. Maybe it is every video should come up with some code now that this is -- this is like authentic video or authentic text. You do not believe anything else. I mean yeah.   But like maybe it was the timing more than anything but I saw this video and it really felt like Oh my God! Like America cannot handle this right now. Like we are in a moment where -- where truth seems to be sort of a -- an open disc -- what is true is -- has become an open discussion. And this seems to be adding fuel on the fire of sort of competing narratives in a way that I find troubling. And I am just curious that you do not.   I think that -- I think that people -- if people know that such technology exists then they will be more skeptical. My guess I do not know. But if people know that fake news exists if they know that fake texts exists fake videos exist fake photos exist then everyone is more skeptical in what they read and see.   But like a man in North -- I think he was from North Carolina believed from a fake print article that Hillary Clinton was running a sex ring out of a pizza parlor in DC which is like insane. This man believed it and showed up with a gun. And if people are at a moment where they are willing to believe stories as ludicrous as that like I do not expect them to wonder if this video is real or not.   So what are you asking?   I am asking -- well I am asking do you -- are you afraid of the power of this? And if not why?   Just -- I am just giving my -- I do not know. It just -- I am answering your questions but I am a technologist I am a computer scientist. So not really because I know how to -- and I know that -- because I know that this technology's reversible. I mean nobody -- well there is not -- not worried too much.   Have you seen these videos? Otherwise I can text it.   I have yeah.   Okay.   Yeah I have.   And as we were feeling worried and more than that surprised that the folks making these technologies were not we decided to do a sort of gut check to see if we were totally off base and get in touch with one of the guys who is on the front lines of this.   Can you describe what was going through your head when you were watching Bush's face?   I can tell you exactly what I was thinking. I was thinking how are we gonna develop a forensic technique to detect this?      This is Hany Farid.   I am a professor of computer science at Dartmouth College.   He is sort of like a Sherlock Holmes of digital misdeeds which means that he spends a lot of time sitting around looking at pictures and videos ...   Trying to understand where has this come from has it been manipulated and should we trust it?   He is done work for all sorts of organizations.   The AP The Times Reuters ...   Who want to know if say a picture is fake or not.   They often will ask me you know particular when -- like this just happened actually yesterday. Images came out of North Korea. And every time images come out of these regimes where there is a history of photo manipulation there are real concerns about this. So I was asked to determine if they would been manipulated in some way and if so how had they been manipulated.   And how -- how the heck would you do that?   Well every time you manipulate data you are gonna leave something behind.   So let us say you do some funny business to a photo. You might create some noticeable distortion in the picture itself but you also might distort the data.   And we are in the business of basically finding those distortions in the data.   For example imagine he gets sent a photo. It is probably a jpeg.   Jpeg which now is 99 of the image formats that we see out there is what is called the lossy compression scheme.   Just a fancy way to say that when a photo is taken and stored as a jpeg the camera you know just to save space throws a little bit of the data away.   So for example if I went out to the Dartmouth Green right now and took a picture of the grass.   The camera is not gonna store all those millions of little variations of green hidden in the grass because that would be just a huge file. Its going to save space by throwing some of those greens away.   You just do not notice if it changes like a lot or a little bit less than that. It is just grass as far as you can tell.   Now here's Hany's trick. Every camera has a subtly different palette of greens that it is going to keep and greens that it is going to throw away.   This varies tremendously from device to device. An iPhone compresses the image much more.   So less greens.   Than a high-end Nikon or a high-end Canon.   Which would keep more of those variations of green. Now if you hold these two pictures side by side you might not be able to tell the difference. But Hany says when you look at the underlying pixels there are different recognizable patterns.   If you take an image off of your iPhone I should be able to go into that jpeg and look at the packaging and say Ah yes this should have come out of an iPhone. But if that image is uploaded to Facebook and then re-downloaded or put it into Photoshop and re-saved it will not look like jpeg consistent with an iPhone.   So basically he can see at the level of the pixels or data whether the picture has been messed with in any way.   Huh.   And this is of course just one of many different ways that Hany can spot a fake.   Yeah. Yeah.   Well let me ask. Like if you could go up against the top 100 best counterfeiters do you think you would catch them 10 percent of the time? 50 percent of the time? Just out of curiosity what is your sense?   I would say we could probably catch 75 percent of the fakes. But I would say that would take a long time to do. This is not an easy task. And so you know the pace at which the media moves does not lend itself to careful forensic analysis of images. I am always amazed that you know you get these emails you are like All right you got 20 minutes. And you would need you know half a day a day per image.   Oh!   So a very manual and a very human process.   So is this video editing and this audio editing that is coming down the pipeline here.   Yeah.   I guess should I be -- should I be terrified?   Um yes you should.   Oh no. Do you really mean that?   Yeah I think it is -- I think it is going to raise the fake news thing to a whole new level. I did see some artifacts by the way in the videos they are not perfect. But that is neither here nor there because the ability of technology to manipulate and alter reality is growing at a breakneck speed. And the ability to disseminate that information is phenomenal. So I cannot stop that by the way because at the end of the day it is always going to be easier to create a fake than to detect a fake.   Thank you very much. Jad himself just handed me a cup of water which shows none of you have gotten too big for your britches.   And that could be a serious problem ...   I would like to have seen Peter Jennings do that ever.   ... for this guy.   My name is Jon Klein co-founder and CEO of Tapp Media.   Before that ...   President of CNN US.   Oh wow.   Before that I was Executive Vice President of CBS News where I was executive in charge of 60 Minutes 48 Hours and a bunch of other things.   And he is had to react to some serious evolutions in the media industry. He was manning the helm as social media exploded as smartphones became ubiquitous and consequently he had to deal with figuring out how and if to trust thousands of hours of video taken on these smartphones and sent in by viewers. What to broadcast and what not to. And so we wanted to know how someone in his position would think about these fake videos. So we sent him all of the different demos and videos we would come across just to see what he thought.   First thought was that this is the kind of thing that a James Bond villain would put to use. Or The Joker in Batman. Or an eighth-grade girl who right wants to be most popular.   Yeah exactly.   Yeah.   You know I mean this is -- there is so many ways to abuse this blows your mind. I mean it goes to the very core of communication of any sort whether it is television or radio or interpersonal. Is what I am seeing true? Is what I am hearing real?   In your -- over the course of your career you have seen multiple technological developments that have impacted the media in rather profound ways. Where is your terror level right now or your fear level caused by this relative to all of the other sort of advancements that have occurred over --over your career?   It is terrifying. And it hurtles us even faster toward that point where no one believes anything. How do you have a democracy in a country where people cannot trust anything that they see or read anymore?   What -- what we saw happen with the fake news during the election cycle was that it does not -- it did not even need to matter if anyone you know would rebuff it afterwards.   This is Nick Bilton again.   It would reach millions and millions of people in mere seconds. And -- and that was it. You would done -- it had done its job. And I think that with this audio stuff and the video stuff that is gonna come down online in the next few years it is gonna do the same thing but no one's gonna know what is real and what is not.     And what is more Nick says ...   If you think about the video that came out of Donald Trump from Access Hollywood.     The thing that was really interesting about that video ...     ... you do not actually see Donald Trump until the very last second when he gets off the bus.     You only hear him.     And so if that technology existed today I can guarantee you that Donald Trump would have responded by saying Oh it is fake. It is fake news it is fake audio. You cannot see me. I did not say that. And it would just be this video's word against his.   Okay actually that is kind of like for me that is sort of the real problem here. Like you create this possibility for like plausible deniability. It is so broad. You know what I mean? It is like -- you know it is like the tobacco industry in the '60s and '70s. You know I was just reading this great article by the writer Tim Harford about this. In the '60s and '70s the tobacco industry led this very calculated effort to sort of push back against cancer science by you know just injecting a little bit of doubt here a little bit of doubt there.   Right but on the other hand ...   On the other hand this and on the other hand that. And the idea was to create just enough wiggle room that nothing happens.   They do that with climate change too.   Exactly. And it is that little bit of doubt that creates a paralysis. And is that what is gonna happen? That like there is gonna be paralysis now writ large because now we are talking about the very things we see the very things we hear.   But wait. But do not you think that before we get completely carried away with the threat of this technology you know maybe we should just find out literally where we are now.   Yeah.   We should give it a spin.   Yeah. Mm-hmm.   So at this moment do you think making one of these clips is possible?   Yeah. I think it is entirely possible. It just -- I would be careful what it is.   After the break things get fake.       Jad.   Robert.   Radiolab.   So we are back. We are going to now fake something. We are going to build our own video from scratch.   Fake words fake faces. Because we wanted to know like in use how dangerous are these technologies really? Can they make a convincing fake? Are they as easy as advertised?   So we will find out by giving the assignment as always to our long-suffering Simon Adler.   So while I was in Seattle talking to Durin Gleaves I not so subtly hinted that I would really like to give VoCo a whirl.   Let us say I had my hands on it somehow.   Absolutely.   What can I do with it?   Well right now nothing because we have not shared it with anybody.   At first I just thought he did not want me to be able to play around with it but then I realized ...   But I do not even have a personal copy for myself yet.   Oh so it is not even on the premises here.   No it is still very much contained to research.   Oh.   But ...   Hiya. Hi are you there?   Hey Matt.   Yeah I am here.   Great.   Eventually I got in touch with this guy.   So I am Dr. Matthew Aylett. I am the Chief Science Officer at CereProc Limited.   Which is a vocal synthesis research company based in Edinburgh.   Yeah.   Okay so I called you up because I was hoping that you could help me to make a video clip that has I do not know like George Bush or Barack Obama saying things that they have never said.   Yep that sounds great.   That is it? He was just game?   Yeah. Now see the thing is what his company does is not quite the same as VoCo. What they do is like for a client they will create a voice that you can then just type in words or sentences and make that voice say whatever you want it to say.     They have created voices with a variety of accents.     In a variety of languages.       And in their spare time when they are not making voices for clients ...     ... they are building celebrity voices. And it just so happens they have got a Barack Obama and a George Bush bot.   Yeah.   How did you create a George Bush robot?   Well a great thing about George Bush is that he was President the United States for some time.     Which means he had to give ...   The weekly presidential address.     And the other great thing about the address is it is completely copyright-free so we are allowed to do anything we like that audio.     Maybe things that they have not envisaged that we are going to do with it.   Real quick digression here just because it is absolutely fascinating. It looks like we are actually about to enter this really sticky gray area when it comes to voice ownership.   For example an audio book ...   So if you record an audio book and you have signed over the rights to those audio files to the publisher ...   The publisher has the copyright.   You do not own it. You do not own your own voice.   Is that really true?   Yeah.   Anyway back to Bush.   So I took all those weekly addresses.   About six hours worth which is a lot more tape than VoCo's 20 minutes. But what he did with it is pretty similar.   Right.   He fed them into this machine-learning algorithm along with their transcripts and then what the program will do ...   It will take the text and it will analyze it in terms of the linguistics. It will say this is the word ...     Social. The word social is made up of the sounds suh-oh-sh-ul right?   Mm-hmm.   And so we will cut those sounds up into lots of little tiny pieces.   And it did that for all of the words in all of these addresses. Around 80000 in total. Put them all in this database with tons of info about what sound came before it after it etcetera.   And ...   Once that database is built all that is left to do ...   I type in some text and then I push go and it will try and find a set of little sounds which will join together really nicely. And then I push play and see how well they came out.   So what we did was we found an old video of former Presidents George Bush and Barack Obama together.     They are shaking hands making generic statements. The exact clip is not important. But we wondered could we turn that clip from a boring meet-and-greet to a scenario where Bush is telling Obama a joke? So we convinced a comedy writer Rachel Axler who works for the show Veep to write us a few jokes and sent it off to Matt and this is what the computer spat out.                  What the hell was that?   Wait what?   That was terrible!   No!   Technically that was like ...   I do not ever get -- a I do not understand that joke at all. And that is literally what the computer spat out?   That is what the computer spat out and truth be told I do not think it is anywhere -- it is not worthy of the negative response that you are giving it.   That is terrible.   That is terrible.   Let me show you another one.     Put what?     Cortisol?         Pretty good!   No the robots are terrible.   I could not hear cortisol.   But the joke is funny. I like the joke. But the robots just massacred that joke. Which is in itself kind of a joke.   Well I do think that -- yeah let me get into it. Well I think that you two are far more critical than you should be and you are far more critical than the average listener. However Matt ...   You are so wrong about that.   But anyway ...   Anyhow.   Matt did tell me that conversations getting people to talk back and forth to each other are still really difficult for a synthesizer to do.   You know conversational stuff is always difficult. And in fact we are going to -- it is going to be a long time before we get really really easy conversational synthesis. There is all sorts of barriers to that.   There is a human quality to a conversation that the synthesizers cannot quite capture yet. But he also told us that you know if we add -- once we add the video or if we add a video to this it will smooth out a lot of the problems.   When you have the faces as well speaking people are not focusing on the audio.   Mm-hmm.   And you cannot hear the errors in the same way.   So ...   Hello?   Hey is this Kyle?   Oh yeah.   Great. Great.   I found these two grad students.   My name is Shunsuke Saito.   I am Kyle Olszewski.   From ...   The University of Southern California.   USC.   They also do a lot of facial reenactment research and agreed to help us. But making these visuals also turned out to be way harder than we thought. Turned out the clip we chose posed some serious challenges. There were too many side shots of Obama's face the lighting was all wrong. And eventually I got an email one late Sunday night saying it is not gonna work.   Okay. So now I think I can draw a line here and I can point out that this -- that we maybe got overexcited about this technology. It is not yet ready for true deceit. You have been fumbling and fumbling and fumbling here.   I have not been fumbling. I am not the running back here.   I find it interesting psychologically that Simon feels like it is a personal failure.   I do not like to fail.   You should. This is ...   So okay. Just -- just on Simon's behalf on behalf of actually trying to answer the question we felt like okay maybe -- maybe we should try this one last time. Let us find a simpler Obama video and with the audio rather than like whole phrases let us just do a couple of word replacements here or there. By the way the only reason we are using Obama is that he seems to be the guy all these technologies are built around. In any case we chose the video of Obama's last weekly address and we chose the audio from a talk he would given in Chicago after he would left office.     In this speech he sort of talks about what he is gonna do next how he is still gonna keep fighting for what he believes is right.     But we thought what if in an alternate reality he did not want to keep fighting? What if he could at that moment see the divisions ahead and he was just like Ah that is too much. I give up. Now truth is we did not think too hard about this because we did not have much time. We just whipped it together. Did a script based on words Obama used with a few changes sent it off to the guys at USC.   And I videotaped myself saying this new script so that we could use that video of my face to puppetize the former president. And when we got the final video back ...   I have to say it was -- I was expecting it to be horrible and we were to have a good laugh but I -- it went from like laughy giggly to -- to Oh wait. This is creepy!   Well yeah. No I was suddenly -- I had been gangbusters we got to release this thing and not tell anybody and try to fake out the entire world. But when I saw it there was a reluctancy.   You mean you went Oh no?   I went Oh God. Yeah. Yeah. I thought Oh this -- this ...   You know my personal thought was like it was convincing enough that I got genuinely spooked. But you know just in fairness we should not sit around talking about something people cannot see. Go to FutureOfFakeNews.com and check it out for yourself. It is all one word. FutureOfFakeNews.com and it will pop right up. You can see tell us what you think. You can see how Simon made the video. Check it out. Anyhow the whole process got us all thinking like Oh wow. If we a bunch of idiots can do this for no money very very quickly. What will this mean to like a newsroom for example? Just to start there.   We are at the level now with this kind of thing where we need technologists to verify or knock down and ...   Again news executive Jon Klein.   I do not think journalists English majors are gonna be the ones to solve this you know? You may have been editor of your school paper but this is beyond your -- your capability. But if you are good at collaborating with engineers and scientists you know you will have a good chance of working together to figure it out. So we need -- we need technical expertise more than we ever have.   Can I ask you in your heart -- let me compare your heart to my heart for a second. In my heart I want somebody to tell the researchers Yeah sorry you cannot do that. Sorry you know I know it is really cool. I know you -- I know you probably are really proud of that algorithm. But some men in black are gonna walk in right now and they are going to take your computers away. And you just cannot. Sorry. Society is going to overrule you right now. Do you -- is there a part of you that just dictatorially wants to just like squash this?   Well sure. But would not you still have the what are they? The FSB in Moscow or the CIA utilizing this and developing it anyway? Weaponizing it so to speak?   Probably.   And I think that the top-down model could never contain that.   Jon says ultimately what is happening is probably going to be bigger than any one organization or any one newsroom can solve. He said it will probably end up coming down to the 14- and 15-year-olds of tomorrow who will grow up using this technology making fake videos being the victims of fake videos and that maybe in the maze of them having to parse truth from fiction in such a personal way some kind of code will develop.   I am an optimist by nature. I do -- I look at this and I say Well somebody's gonna figure it out. What worries me is the larger context within which this takes place. This is all occurring within a context of massive news illiteracy and the -- the consumers seem to be just throwing their hands up and tiring of trying to even figure it out. And so just the work involved in getting to the bottom of the truth is unappealing to a growing percentage of the audience. And I am not sure where Gen Z the teenagers of today come out on this. Let us hope that they are more willing to do the work maybe out of self-interest maybe so that they are not dissed by you know the girl in social studies. But that is our best hope for overcoming it because everybody else seems to be sick of trying.   Reporter Simon Adler. This piece was produced by Simon and Annie McEwen. Very special thanks to Kyle Olszewski and the entire team at USC's Institute for Creative Technology for all their work manipulating that video of President Obama. And thanks to Matthew Aylett for synthesizing so so many words for us. Rachel Axler for writing us the jokes that we tried to use. Sohum Pawar for building us an amazing website Angus Kneale Amy Pearle everybody in the WNYC newsroom for advising us and giving us reaction shots to the face-to-face video.   And to David Carroll for putting us in touch with Nick Bilton in the first place. And to Nick Bilton for inspiring this whole story with his article. He is got a new one -- a book actually American Kingpin about the founder of a black market website called The Silk Road. And to Supasorn Suwajanakorn a computer scientist who works in Ira's lab who helped us understand what the heck was going on.   And finally you can see the video that we created as well as a bunch of other kind of crazy clips that we mentioned throughout this episode. It is at FutureOfFakeNews.com. It is all one word. FutureOfFakeNews.com. And with that my real co-host and I will bid you adieu.   I am Jad Abumrad.   I am Robert Krulwich.   That is who we really are.   I am glad we could finally be honest about that.   Yeah. All these years.                      -30- 