 Okay so in the layer cake of mayhem that we find ourselves in -- that metaphor makes no sense -- I want to update a story that we played a few years ago that is fascinating but definitely shifting and changing as we speak. And worth tracking and yet hard to track with all the things that are happening right now. This is a story that aired I believe two years ago but still very timely. As you will hear a bit later in the episode we will come back around and update it bring it up to the present.     Hey I am Jad Abumrad.   I am Robert Krulwich.   This is Radiolab.   And today we have a story about what we can say ...   And what we -ing cannot.      And by the way there is gonna be a smattering of curse words here that we are not gonna bleep which I think makes sense given the content of this story. And also there is some graphic scenes that if you have got kids with you you may want to sit this one out.   Yeah. Anyway the story comes to us from producer Simon Adler.   So let us start. Can we start in 2008?   Sure.   How about with a song?   Yes please.     So December 27th a sunny Saturday morning this group of young to middle-aged women gathered in downtown Palo Alto.     They are wearing these colorful hats and are singing and swaying directly in front of the glass-doored headquarters of ...     Yes. It was a humble gathering of a few dozen women and babies.   That right there ...     ... is one of the organizers of the gathering.   I am Stephanie Muir.       Nurse-in as in like breastfeeding.   The intent was really just to be visible and be peaceful and make a quiet point.   What -- what point were they trying to make?   Well so Stephanie and this group of mothers you know they were on Facebook as many people were and they would have photos taken of themselves occasionally breastfeeding their babies. They wanted to share with their friends what was going on so they would upload those photos to Facebook. And these pictures would get taken down and they would receive a warning from Facebook for ...   Uploading pornographic content. And people were really getting their backs up over this.   They wanted Facebook to stop taking their photos down. To say that while nudity is not allowed ...   Breastfeeding is exempt period.     Now what Stephanie could not have known at the time was that this small peaceful protest would turn out to be ...     ... one of the opening shots ...     ... in what would become a loud ...       ... raucous ...     ... and global battle.       And now I am not talking about all the things you have recently heard about Russian interference and election meddling or data breaches. But rather something that I think is deeper than both of those Free speech.     What we can say and what we cannot say.       What we can see and what we cannot see ...     ... on the Internet.         But what really grabbed me was discovering that underneath all of this is an actual rule book a text document that dictates what I can say on Facebook what you can say on Facebook and what all 2.2 billion of us can say on Facebook.   For everyone in the entire globe who is on Facebook.   For everyone there is one set of rules that all 2.2 billion of us are expected to follow.   This is an actual document?   It is a digital document but yes it is about 50 pages if you print it off. And in bullet points and ifthen statements it spells out sort of a First Amendment for the globe. Which made me wonder like what are these rules? How were they written?   And can you even have one rule book?   Right. Exactly. And so I dove into this rule book and dug up some stories that really put it to the test.   Hmm. Okay.   I will be interested to hear that.   How many stories are we going to hear?   Three-ish.   Three-ish?   Okay.   Okay.   All right. Cool.   I am particular interested in the -ish. But let us go ahead with the first one.   Well so let us start back on that morning in 2008 the morning that you could argue started at all.     Because in the building right behind those protesting mothers there was a group of Facebook employees sitting in a conference room trying to figure out what to do.   Cool. So if I -- so I am just gonna -- so I should just read this?   So I was able to get in touch with a couple of former Facebook employees one of whom was actually in that room at that moment. And now neither of these two were comfortable being identified but they did give us permission to quote them extensively.   How is that? Will that take work for you?   It sounded great.   Cool.   Just so we have it let us ...   So what you are going to hear here is an actor we brought into read quotes taken directly from interviews that we did with these two different former Facebook employees.   All right. Ready. So at the time when I joined them there was a small group 12 of us.   Mostly recent college grads.   Who were sort of called the Site Integrity Team.   Again keep in mind this was in the early 2000s.     This was like the deep dark past.     Facebook had somewhere in the neighborhood of 10 million users.   We were smaller than MySpace.   The vast majority of them college kids. And so in those early days those 12 people they would sit around in a sort of conference-like room with a big long table each of them in front of their own computer.   And things would come up onto their screen flagged to Facebook and ...   Flagged meaning like I a user saw something that I thought was wrong.   Exactly. Like reporting a piece of content that you think violates the community standards.   This is Kate Klonick. She is a professor of law at St. John's. And she spent a lot of time studying this very thing. And she says in those early days what would happen is a user would flag a piece of content and then that content along with an alert would get sent to one of those people sitting in that room. It would just pop up on their screen.   Most of what you were seeing was either naked people blown-off heads or things that there was no clear reason why someone had reported because it was like a photo of a golden retriever and people are just annoying.   And every time something popped up onto the screen the person sitting at that computer would have to make a decision whether to leave that thing up or take it down. And at the time if you did not know what to do ...   You would turn to your pod leader who was you know somebody who had been around nine months longer than you and ask What do I do with this? And they would either have seen it before and explain it to you or you both would not know and you would Google some things.   It really was just kind of an ad hoc approach.   And was there any sort of written standard or any common standard?   Well kind of.   They had a set of community standards but at the end of the day they were just kind of -- it was one page long and it was not very specific.   Sorry the guidelines were really one page long?   They were one page long.   And basically all this page said was Nudity is bad. So is Hitler.   And if it makes you feel bad take it down.   And so when one of the people sitting in that room would have a breastfeeding picture pop up on the screen in front of them they would be like I can see a female breast. So I guess that is nudity and they would take it down. Until ...     Rise up! Fight for the rights to have breastfeeding -- anyway.   Now a dozen or so people in front of their offices on a Saturday it probably was not causing Facebook too much heartache but ...   I thought You know hey we have an opportunity here with you know over 10000 members in our group.   According to Stephanie Muir those protesters were just a tiny fraction of a much larger online group who had organized ironically enough through Facebook.   So to coincide with the live protest I just typed up a little blurb encouraging our members that were in the group to do a virtual nurse-in.   A virtual nurse-in?   Right. What we did ...   They posted a message asking their members ...   To for one day change their profile avatar to an image of breastfeeding and then change their status to the title of our group Hey Facebook Breastfeeding is Not Obscene.   And ...   It caught on.     Big time.   12000 members participated and the media requests started pouring in.     I did hundreds of interviews for print. Chicago Tribune Miami Herald Time Magazine New York Times Washington Post ...     ... Dr. Phil. It was a media storm. And eventually perhaps as a result of our group and our efforts Facebook was forced to get much more specific about their rules.   So for example by then nudity was already not allowed on the site. But they had no definition for nudity. They just said no nudity. And so the Site Integrity Team those 12 people at the time they realized they had to start spelling out exactly what they meant.   Precisely. All of these people at Facebook were in charge of trying to define nudity.   So I mean yeah the first cut at it was visible male and female genitalia. And then visible female breasts. And then the question is well okay how much of a breast needs to be showing before it is nude? And the thing that we landed on was if you could see essentially the nipple and areola then that is nudity.   And it would have to be taken down. Which theoretically at least would appease these protesters because you know now when a picture would pop up of a mother breastfeeding as long as the child was blocking the view of the nipple and the areola they could say Cool no problem.   Then you start getting pictures that are women with just their babies on their chest with their breasts bare. Like for example maybe baby was sleeping on the chest of a bare-breasted woman and not actively breastfeeding.   Okay now what? Like is this actually breastfeeding? No it is actually not breastfeeding. The woman is just holding the baby and she has her top off.   Yeah but she was clearly just breastfeeding the baby.   Well maybe just before.   Well I would say it is sort of like kicking a soccer ball. Like a photo of someone who has just kicked a soccer ball you can tell the ball is in the air but there is no contact between the foot and the ball in that moment potentially. So although it is a photo of someone kicking a soccer ball they are not in fact kicking the soccer ball in that photo.       That is a good example.   And this became the procedure or the protocol or the approach for all of these things was we have to base it purely on what we can see in the image.   And so they did not allow that to stay up under the rules because it could be too easily exploited for other types of content like nudity or pornography.   We got to the only way you could objectively say that the baby and the mother were engaged in breastfeeding is if the baby's lips were touching the woman's nipple.   So they included what you could call like an attachment clause. But as soon as they got that rule in place ...   Like you would see you know a 25-year-old woman and a teenage-looking boy right? And like what the hell is going on there?   Oh yeah. It gets really weird if you like start entering into like child age. And I was not even gonna bring that up because it is kind of gross.   It is like breastfeeding porn.   Is that a thing?   Are there sites like that?   Apparently. And so this team they realized they needed to have a nudity rule that allowed for breastfeeding but also had some kind of an age cap.   So -- so then we were saying Okay. Once you have progressed past infancy then we believe that it is inappropriate.   But then pictures would start popping up on their screen and they would be like Wait. Is that an infant? Like where is the line between infant and toddler?   And so the thing that we landed on was if it looked like the child could walk on his or her own then too old.   Big enough to walk? Too big to breastfeed.   Oh that could be 18 months.   Yeah that is like a year old in some cases.   Yeah. And like the World Health Organization recommends breastfeeding until you know like 18 months or two years which meant there were a lot of photos still being taken down.   Within days we were continuing to hear reports from people that their photographs were still being targeted.   But ...     You know that is where we are going to draw the line.     And keep in mind through this whole episode ...     The company was growing really really fast.     And there just got to be a lot more content.     Thousands more people are joining Facebook every day.       Not just within the United States but also ...   It was growing rapidly more international.   You know you were getting stuff from India and Turkey.     It is getting big throughout the EU.     So they have more and more content coming in from all these different places in all these different languages.   How are we going to keep everybody on the same page?   And so once they saw that this was the operational method for dealing with this creating this like nesting set of exceptions and rules and these clear things that had to be there or had to not be there in order to keep content up or take it down that I think became their procedure.   And so this small team at Facebook got a little bigger and bigger. Jumped up to 60 people and then a hundred. And they set out to create rules and definitions for everything.   Huh.   Can we go through some of sort of the ridiculous examples?   Yes please.   That is why we are here.   Okay. So gore.   Gore. You mean violence kind of gore?   Yes. So the gore standard was headline ...   We do not allow graphic violence and gore.   And then the shorthand definition they used was ...   No insides on the outside.   No guts no blood pouring out of something.   Blood was a separate issue. There was an excessive blood rule. They had to come up with rules about bodily fluids.   Semen for example would be allowed in like a clinical setting but like what does a clinical setting mean? And you know does that mean if someone is in a lab coat?   Hmm.   One of my favorite examples is like how do you define art?   Because as these people are moderating they would see images of naked people that were paintings or sculptures come up.   Oh.   And so what they decided to do was say Art with nakedness can stay up.   Like it stays up if it is made out of wood made out of metal made out of stone.   Really?   Yeah. Because how else do you define art? You have to just be like is this what you can see with your eyeballs?   And so from then on as they run into problems ...   Those rules just constantly get updated.   Constant amendments.   Yeah constant amendments.   New problem new rule. Another new problem updated rule. In fact at this point they are amending these rules up to 20 times a month.   Wow! Really?   Really?   Yeah. Take for example those rules about breastfeeding. In 2013 they removed the attachment clause. So the baby no longer needed to have its mouth physically touching the nipple of the woman. And in fact one nipple andor areola could be visible in the photo.   But not two.   Only one. Then 2014 they make it so that both nipples or both areolae may be present in the photo.   So this is what happens in American law all the time this very thing.   Yes.   Yeah. You know it sounds a lot like common law.   So common law is this system dating back to early England where individual judges would make a ruling which would sort of be a law but then that law would be amended or evolved by other judges. So the body of law was sort of constantly ...   Fleshed out in face of new facts.   Literally every time this team at Facebook would come up with a rule that they thought was airtight ka-plop something would show up that they were not prepared for that the rule had not accounted for.   As soon as you think yeah this is good like the next day something shows up to show you yeah you did not think about this.   For example sometime around 2011 this content moderator is going through a queue of things.     And she comes upon this image.     The photo itself was a teenage girl African by dress and skin breastfeeding a goat. A baby goat.   The moderator throws her hands up and says ...   What the fuck is this? And we Googled breastfeeding goats and found that this was a thing. It turns out it is a survival practice.   According to what they found this is a tradition in Kenya that goes back centuries. That in a drought a known way to help your herd get through the drought is to -- if you have a woman who is lactating to have her nurse the kid the baby goat along with her human kid.   Hmm.   And so there is nothing sexual about it.   Just good farming.   Good business.   And theoretically if we go point by point through this list it is an infant. It sort of could walk so maybe there is an issue there. But there is physical contact between the mouth and the nipple.   But -- but ...   Obviously ...   Breastfeeding as we intended anyway meant human infants.   And so in that moment what they decide to do is remove the photo.   And there was an amendment an asterisk under the rules stating animals are not babies. We added that so in any future cases people would know what to do.   They removed -- they discover it was culturally appropriate and a thing that people do and they decided to remove the photo?   Yeah.   That outraged individual is our editor Soren Wheeler.   Why?   Why did not we make an exception?   Because ...   Because when a problem grows large enough you have to change the rules. If not we do not. This was not one of those cases. The juice was not worth the squeeze.   And like if they were to allow this picture then they would have to make some rule about when it was okay to breastfeed an animal and when it was not okay.   This is a utilitarian document. It is not about being right 100 percent of the time. It is about being able to execute effectively.   In other words we are not trying to be perfect here and we are not even necessarily trying to be 100 percent just or fair we are just trying to make something that works.   One two three four five six seven eight.   And when you step back and look at what Facebook has become like from 2008 to now in just 10 years ...   Simon I have just arrived at the Accenture Tower here in Manila. I do not know how many floors it is. One two three four five ...   The idea of a single set of rules that works that can be applied fairly ...   That is just a crazy crazy concept.   15 16 17 18 ...   Because they have gone from something like 70 million users to 2.2 billion.   It is hard to count but I would say it is about 30 floors.   And they have gone from 12 folks sitting in a room deciding what to take down or leave up to somewhere around 16000 people.   So there is a floor in this building where Facebook supposedly outsources content moderators.   And so around 2010 they decided to start outsourcing some of this work to places like Manila where you just heard reporter Aurora Almendral as well as ...   I mean I would guess that there are thousands of people in this building.   ... Dublin where we sent reporter Gareth Stack.   Oh I can see where they get their delicious Facebook treats cooked. Everybody's beavering away.   And we sent them there to try to talk to some of these people who for a living sit at a computer and collectively click through around a million flagged bits of content that pop up onto their screen every day.   Wow. I am just curious what is that like?   Well ...   Hello. Can I ask you some questions?   Sorry.   We found out pretty quickly ...   Who do you work for?   ... none of these folks were willing to talk to us about what they do.   So there is a lot of running away from me happening.   Hey lads sorry to bother you do you guys work at Facebook?   Ah no. Sorry.   Do you happen to work in Facebook by any chance?   No I do not.   Hi. Sorry to bother you do you work inside?   No. Sorry.   Do you work in Facebook?   No.   I mean you just came out of there. I know you are lying.   In fact most people would not even admit they work for the company.   Like what is the -- is there something wrong about being in the ...   Do they have like an NDA that they signed?   Well yeah. So when I finally did find someone willing to talk to me ...   Do you want to be named or do you not want to be named?   I would rather not.   That is totally fine.   You know I am still in the industry. I do not want to lose my job over this shit you know?   He explained that he and all the other moderators like him were forced to sign these non-disclosure agreements stating they were not allowed to admit that they work for Facebook they are not allowed to talk about the work they do ...   My contract prohibited me from talking about what content moderation was.   Why?   Several reasons. One is that up until recently Facebook wanted to keep secret what these rules were so that they could not be gamed.   Oh.   At the same time it creates a sort of separation between these workers and the company which if you are Facebook you might want ...   You know I knew I signed up to monitor graphic images.   ... just given the nature of the job.   But you know I did not really -- you know you do not really know the impact that that is going to have on you until you go through it.   So this guy I talked to he got his first contract doing this work several years back. And for the duration of it about a year he would show up to his desk every morning put on his headphones ...   Click click click click click click click.   Ignore delete delete.   Case by case by case by case. 5000 cases every day. It was just image and decision. Image decision image decision.   Wait 5000 a day you just said?   Yeah. It was a lot of cases.   Yeah he said basically he would have to go through an image or some other piece of content every three or four seconds.   Wow. All day long?   All day eight hours a day.   Whoa.   Well if I can ask what kind of things did you see?   I do not know if this is even like radio-worthy. I think it is too x-rated.   Clicking through he came across unspeakable things.   From heads exploding to you know people being squashed by a tank to people in cages being drowned to like a 13-year-old girl having sex with an 8-year-old boy. And it is not just once it is over and over and over and over.   Well and did you -- did this like keep you up at night? Or did this ...?   Absolutely. Absolutely 100 percent. It kept me up at night.   He would catch himself thinking about these videos and photos when he was trying to relax. He had to start avoiding things.   There were -- there were specific like movies that I could not watch. There was one I think it was Quentin Tarantino one my wife wanted to see it. I was like Okay. I turned it on. It was like heads were exploding. I was like Nope nope. I have to walk away. And I just -- I had to. It was too real. I saw that. It is classic PTSD.   A different moderator I spoke to described it as seeing the worst side of humanity. You see all of the stuff that you and I do not have to see because they are going around playing clean-up.   Yeah.   What a job. Wow.   Yeah. And it is worth noting that more and more of this work is being done in an automated fashion particularly with content like gore or terrorist propaganda. They are getting better.   You can automate that?   Yeah. They through computer vision they are able to detect hallmarks of a terrorist video or of a gory image and with terrorist propaganda they now take down 99 percent of it before anyone flags it on Facebook.   Wow.   But moving onto our second story here there is a type of content that they are having an incredibly hard time not just automating but even getting their rules straight on and that is surrounding hate speech.   Oh good. Some more laughs coming up.      Well there will be laughter.   Oh really?   There will be comedians. There will be jokes.   Okay. Comedians.   Hey!   All right.   Okay.   Well shall we take a break and then come right back?   No I think we are gonna keep going.   Okay.   Testing. One two three four five. Testing. One two three four five. I am Simon Adler.   So a couple months back ...   I think it is working.   Great.   ... we sent our pair of interns.   On the left 60 feet.   Carter Hodge ...   Here we go at The Standing Room.   ... and Liza Yeager ...   Do you guys have tickets for tonight?   I think we are on the guest-list.   Okay.   ... to this cramped narrow little comedy club. The kind of place with like ...   It is super expensive.   I know.   ... 15 smashed rosemary cocktails.   What is going on?   None of it. We do not need to get a drink. It is fine.   High-top tables.   The AC is dripping on me.   But still kind of a dive.   That feels good. Yeah.   And we sent them there to check out someone else who would found a fault line in Facebook's rulebook.   This is exciting. We are gonna keep moving right along. The next comedian coming to the stage please give it up for Marcia Belsky!   Thank you. Yes. I get so mad. I feel like my first time to the city I was such a carefree brat. You know I was young and I had these older friends which I thought was like very cool and then you just realize that they are alcoholics you know?   She is got dark curly hair was raised in Oklahoma.   And I think -- I was raised Jewish. So when you are raised Jewish you read about Anne Frank a lot. You know a lot a lot. And when you read about Anne Frank like -- this will get funny. She ...   How did you decide to become a comedian?   You know it was kind of the only thing that ever clicked with me. And especially political comedy. You know I used to watch the Daily Show every day.   And back in 2016 she started this political running bit that I think can be called sort of absurdist feminist comedy.   Now a lot of people think that I am like an angry feminist. Which is weird. This guy called me a militant feminist the other day and I am like Okay. Just because I am training a militia of women in the woods.   At first I just had this running bit online on Facebook and Twitter.   She was tweeting and posting jokes.   You know like we have all the Buffalo Wild Wings surrounded. You know things like that.   Eventually took this bit on stage even wrote some songs.    All older white men should die but not my dad. No no not my dad.         Anyhow so about a year into this running bit Marcia was bored at work one day and logs onto Facebook. But instead of seeing her normal news feed there was this message that pops up.   It says You posted something that discriminated along the lines of race gender or ethnicity group.   And so we have removed that post.   And so I am like What could I possibly have posted? I really -- I thought it was like a glitch.   But then she clicked Continue and there highlighted was the violating post. It was a photo of hers.   What is the picture? Can you describe it?   The photo is me as what can only be described as a cherub cute little seven-year-old with big curly hair and she is wearing this blue floral dress her teeth are all messed up.   And into the photo Marcia had edited in a speech bubble ...   That just says Kill all men. And so it is funny you know because I hate -- I hate -- it is funny you know? Trust me. Whatever. So I thought it was ridiculous because I ...   So she searched through her library of photos and found that Kill all men image.   And I post it again.   Immediately after? Like ...   Yeah. And it got removed again.   And this time there were consequences.   I got banned for three days after that.   Then after several other bans ...   Shoot forward this is months later.   ... a friend of hers had posted an article and underneath it in the comments section there were guys posting just really nasty stuff.   So I commented underneath those comments Men are scum. Which was very quickly removed.   And how long did you get banned for this time?   30 days.   Wow!   Yeah. I was dumbfounded.   So there is a rule somewhere that if I type Men are scum you take it down?   Yes.   I am like What could it be?   And so Marcia called on her quote militia of women.   Exactly.   To find out like is this just me?   Female comedians who are sort of like mad on my behalf started experimenting posting Men are scum to see how quickly it would get removed and if it would be removed every time. And it was.   So they started trying other words.   Woof. Yeah.   To find out where the line was.   My friend put Men are da scum. That got removed. Men are the worst.   Removed and banned.   This one girl put Men are septic fluid. Banned.   But ...   We are only at the middle of the saga.   It does not end there.   Because there is no ...   Now she is really like What the hell is going on? Is this sexism?   So I just start doing the most bare minimum amount of investigating.   She is Googling around trying to figure out what these policies are. And pretty quick she comes across this leaked Facebook document.   So this is when I lose my mind. This is when Mark Zuckerberg becomes my sworn nemesis for the rest of my life.   Because what she would found was a document Facebook used to train their moderators. And inside of it in a section detailing who Facebook protected from hate speech there was a multiple choice question that said Who do we protect? White men or Black children? And the correct answer was white men not Black children.   Not even kidding.   White men are protected Black children are not. That is not a good look.   It is racist. Something's going on here. There is absolutely some sort of unaddressed bias or systematic issue at Facebook.   Hi.   Hello.   How are you?   I am doing well. Thank you so much for being willing to do this.   Yeah. No.   So not long after sitting down with Marcia Facebook invited me to come out to their offices in California and sit down with them.   I am gonna eat one cookie and then we are on. Ooh they are little. I think I get two.   Could I just get your name and your title?   I am Monika Bickert and I lead the policies for Facebook.   Monika Bickert is in charge of all of Facebook's rules including their policies on hate speech. And so I asked her like why would there be a rule that protects white men but not Black children?   We have made our hate speech policies -- let me rephrase that. Our hate speech policies have become more detailed over time but our main policy is you cannot attack a person or group of people based on a protected characteristic. A characteristic like race religion or gender.   So this takes a couple of beats to explain but the gist of it is that Facebook borrowed this idea of protected classes straight from U.S. anti-discrimination law. These are the laws that make it so that you cannot not hire someone say based on their religion their ethnicity their race. And so on Facebook you cannot attack someone based on one of these characteristics. Meaning you cannot say Men are trash. Nor could you say Women are trash because essentially you are attacking all men for being men.   Oh is it the All? Can I say Bob is trash?   Yeah. You can say Bob is trash. Because as my sources explained to me ...   The distinction is that in the first instance you are attacking a category. In the second instance you are attacking a person but it is not clear that you are attacking that person because they are a member of a protected category.   Oh so Bob might be trash for reasons that have nothing to do with him being a man.   Yeah.   He just might be annoying.   Right.   Okay so that explains why you would take down Men are scum. But why would you leave up Black children are scum? Why would that not get taken down?   So traditionally we allowed speech once there was some other word in it that made it about something other than a protected characteristic.   In Facebook jargon these are referred to as a non-protected modifier.   This means literally nothing to me. Give us an example of this?   So traditionally if you said I do not like 'this religion' cab drivers.   'Cab driver' would be the non-protected modifier because employment is not a protected category.   Huh.   And so what the rule stated was when you add this non-protected modifier to a protected category in this case the cab driver's religion ...   We would allow it because we cannot assume that you are hating this person because of his religion. You actually just may not like cab drivers.   So in the case of Black children children is modifying the protected category of Black.   Mm-hmm.   And so 'children' trumps 'Black?'   Age is a non-protected category.   Okay.   And so 'children' becomes a non-protected modifier and their childness trumps their Blackness. You can say whatever you want about Black children. Whereas in the case of white men you have got gender and race both protected you cannot attack them.   That is just a bizarre rule. I would think you would go the other direction that the protected class would outweigh the modifier.   Well they made this decision as they explained to me because their default was to allow speech. They were really trying to incorporate or nod to the American free speech tradition.   And so there is a whole lot of stuff out there that none of us would defend as valuable speech but did not rise to the level of stuff that we would say This is so bad we are going to take it down.   And in this case their concern was ...   We are all members of like you know at least half a dozen protected categories. Like we all have gender we all have sexual orientation.   If the rule is that any time a protected class is mentioned it could be hate speech what you are doing at that point is opening up just about every comment that is ever made about anyone on Facebook to potentially be hate speech.   Then you are not left with anything right?   No matter where we draw this line there are going to be some outcomes that we do not like. There are always going to be casualties. That is why we continue to change the policies.   And in fact since Marcia's debacle they have actually updated this rule. So now Black children are protected from what they consider the worst forms of hate speech.   Now our reviewers take how severe the attack is into consideration.   But despite this there are still plenty of people ...   That is flawed because you are a social network ...   ... including Marcia who think this still just is not good enough.   There are not systematic efforts to eliminate white men in the way that there are other groups. That is why you have protected groups.   She thinks white men and heterosexuals should not be protected.   Protect the groups who are actually victims of hate speech.   Makes sense.   Well yeah. Because in sort of hate speech or thinking about hate speech there is this idea of privileged or of historically disadvantaged groups and that those historically disadvantaged groups should have more protection because of being historically disadvantaged.   Mm-hmm.   And the challenge with that that was presented to me was okay ...     In the 1940s ...     ... you had Japanese soldiers ...     ... killing millions of Chinese during World War Two. At that same time you had Japanese American citizens ...     ... being put into internment camps.   And so we had to ask ourselves a question like are the Japanese an historically advantaged or disadvantaged group?   Huh.   Japanese Americans pretty easy to make a case that they were disadvantaged. But in China it is a totally different story. And this happened at the exact same moment. So you have got two different places two different cultural stories. And when you have a website like Facebook this trans-national community they realized or they decided that ideas of privilege are so geographically bound that there is no way to effectively weigh and consider who is privileged above who and decided therefore that we are not going to allow historical advantage or historical privilege into the equation at all. And I think it is very important to keep in mind here ...     ... these moderators only have like four or five seconds ...     ... to make a decision.     In those four seconds is there enough time to figure out where in the world someone is particularly given IP addresses can easily be masked?     Is there enough time to figure out a person's ethnicity?     On top of that we often do not know an individual's race.     Other categories are even less clear like sexual orientation.   And they just realized it would be next to impossible to get anybody to be able to run these calculations effectively.   When we were building that framework we did a lot of tests and we saw sometimes that it was just too hard for our reviewers to implement a more detailed policy consistently. They just could not do it accurately. So we want the policies to be sufficiently detailed to take into account all different types of scenarios but simple enough that we can apply them consistently and accurately around the world. And the reality is anytime that the policies become more complicated we see dips in our consistency.   What Facebook's trying to do is take the First Amendment this high-minded lofty legal concept and convert it into an engineering manual that can be executed every four seconds for any piece of content from anywhere on the globe. And when you have got to move that fast sometimes justice loses.   That is the -- that is the tension here. And I just want to make sure I emphasize that these policies they are not gonna please everybody. They often do not please everybody that is working on the policy team at Facebook. But if we want to have one line that we enforce consistently then it means we have to have some pretty objective black and white rules.   But when we come back those rules ...   They get toppled.   Jad.   Robert.   Radiolab.   Back to Simon Adler.   Facebook.   Free speech.   So as we just heard before the break Facebook is trying to do two competing things at once. They are trying to make rules that are just but at the same time can be reliably executed by thousands of people spread across the globe in ways that are fair and consistent. And I would argue that this balancing act was put to the test April 15th 2013.       Monday the 15th 2013 just before three in the afternoon two pressure cooker bombs rip through the crowd near the finish line of Boston Marathon. And as sort of the dust begins to settle ...     ... people like springing into action. This one man in a cowboy hat sees this spectator who is been injured picks him up throws him in a wheelchair. And as they are pushing him through this sort of ashy cloud there is this photographer there and he snaps this photo. And the photo shows that the runner in the cowboy hat and these two other people pushing this man who his face is ashen from all of the debris his hair is sort of standing on end and you can tell that actually the force of the blast and then the particles that got in there are actually holding it in this sort of wedge shape. And one of his legs is completely blown off and the second one is blown off below the knee other than the femur bone sticking out and then sort of skin and muscle and tendons. It is horrific. Meanwhile ...     ... on the other side of the country.     I remember snippets of the day.   Facebook employees were clustering around several desks staring at the computer screens watching the news break.     I have memories of watching some of the coverage.     I remember seeing the photo published online. And it was not long after that someone had posted it on Facebook.   From the folks I spoke to the order of events here are a little fuzzy. But pretty quickly this photo's going viral.   And we realized we are going to have to deal with it.   This image is spreading like wildfire across their platform. It appears to be way outside the rules they would written but it is in this totally new context. So they got their team together and sat down in a conference room.   I do not know there was probably eight or ten people thinking about like should we allow it?   Or should they take it down? According to their rules ...   Yeah. So if you recall the no insides on the outsides definition that we had in place meaning you cannot see like people's organs or that sort of thing. And if you can then we would not allow it. And in this photo you could see -- you could definitely see bone.   And so by the rules the photo should obviously come down.   Yep.   However half the room says no.   The other people are saying this is newsworthy.   Essentially this photo's being posted everywhere else. It is important. We need to suspend the rules we need to make an exception. Which immediately receives pushback.   Well I was saying that what we have prided ourselves on was not making those calls. And there are no exceptions. There is either mistakes or improvements.   We made the guidelines for moments like this.   Hmm.   To which the other side shoots back ...   Oh my God are you kidding me? Like the Boston Globe is publishing this all over the place and we are taking it down? Like are you fucking kidding me?   Damn the guidelines let us have common sense here. Let us be humans. We know that this is important.   And yeah they are kind of -- they are right. But the reality is like if you say Well we allowed it because it is newsworthy how do you answer any of the questions about any of the rest of the stuff?   In other words this is a Pandora's box. And in fact for reasons that are not totally clear Team Consistency Team Follow-the-Rules eventually wins the day. They decide to take the photo down. But before they can pull the lever word starts making its way up the chain.   And internally within Facebook ...   According to my sources an executive under Zuckerberg sent down an order.   ... we were essentially told Make the exception.   Huh.   I do not care what your guidelines say I do not care what your reason is the photo stands. You are not taking this down.   Yes. Yes that is what happened.   This decision means that Facebook has just become a publisher. They do not think maybe they have but they have made a news judgment. And just willy-nilly they have become CBS ABC New York Times Herald Tribune Atlantic Monthly and all these other things. All at once they have just become a news organization.   Yeah. And this brings up a legal question that is at the center of this conversation about free speech. Like is Facebook a sort of collective scrapbook for us all? Or is it a public square where you should be able to say whatever you want? Or yeah is it now a news organization?     And this question has been popping up a lot recently. In fact it even came up this past April when Zuckerberg was testifying in front of Congress.               Basically Zuckerberg and others at the company are arguing no they are not a news organization.   Why? What would be the downside of that?   Well Facebook currently sits on this little idyllic legal island where they cannot be held liable for much of anything they are subjected to few regulations. However were they to be seen in the eyes of the court as a media organization that could change. But setting that aside what really strikes me about all of this is here you have a company that really up until this point has been crafting a set of rules that are both as objective as possible and can be executed as consistently as possible. And they have been willing to sacrifice rather large ideas in the name of this. For example privilege which we talked about they decided was too geographically bound to allow for one consistent rule. But if you ask me there is nothing more subjective or geographically bound than what people find interesting or important what people find newsworthy.   Hmm.   And I will give you a great example of this that happened just six months after the Boston Marathon bombing when this video starts being circulated out of northern Mexico. And it is a video of a woman being grabbed and forced onto her knees in front of a camera. And then a man with his face covered grabs her head pulled her head back and slices her head off right in front of the camera. And this video starts being spread.   I cannot count how many times like just reading my Twitter feed I have been like Ah! You know?   One person who came across this video or at least dozens of others like it was Shannon Young.   My name is Shannon Young. I am a freelance radio reporter. I have been living here in Mexico for many years now.   Her beat is covering the drug war. And doing so years back she noticed this strange phenomenon.   It first caught my attention in early 2010.   She would be checking social media.   You know you are scrolling through your feed and you would see all this news. People say Ah! There was this three-hour gun battle and intense fighting all weekend long.   Folks were posting about clashes between drug cartels and government forces. But then when Shannon would watch the news that night ...     ... she would see reports on the economy and soccer results but ...   The media was not covering it.   ... there would be no mention of these attacks.   Nothing to do with the violence.   And so she and other journalists tried to get to the bottom of this.   Reporters in Mexico City would contact the state authorities and you know public information officer and they would be like ...   Shootings? Bombings? What are you talking about?   Nothing's going on. We have no reports of anything. These are just internet rumors.   The government even coined a term for these sorts of posts.   The famous phrase at the time was Collective psychosis. These people are crazy.   Because you know they did not want the situation to seem out of control. But then a video was posted. It opens looking out the windshield of a car on a sunny day. The landscape is dry dusty and the video itself is shaky clearly shot on a phone. And then the woman taping starts talking.   And this woman she just narrates as they drive along this highway.   She pans the phone from the passenger window to the windshield focusing in on these two silver destroyed pickup trucks.   And she is saying Look at these cars over here they are you know shot up and ooh ooh look here look here. You know this 18-wheeler is totally abandoned. It got shot up.   At one point she sticks the phone out the window to show all of the bullet casings littering the ground.   And she just turned the official denial on its head.   The government was saying there is no violence. Here were cars riddled with bullets. It was impossible to dismiss.   And from then on you had more and more citizens citizen journalists uploading anonymously video of the violence.   These low-fi shaky shots of ...   Shootouts dismemberments beheadings. I mean bodies hanging dangling off of overpasses to prove to the world that this was really happening. To say We are not crazy.   It is a cry for help.   Yeah. Which brings us back to that beheading video we mentioned a bit earlier.   Yeah. That video of the beheading a lot of people were uploading it condemning the violence of the drug cartels.   And when it started showing up on Facebook much like with the Boston Marathon bombing photo this team of people they sat down in a room looked at the policy and weighed the arguments.   And my argument was it was okay by the rules during the Boston bombing why is not it okay now?   Particularly given that it could help.   Leaving this up means we warn hundreds of thousands of people of the brutality of these cartels. And so we kept it up. However ...       When people found out ...     ... backlash.     People as powerful as David Cameron weigh in on this decision ...     ... saying we have to protect children from this stuff.     Yep. People were really upset because of what it was showing.   And so according to my sources some of the folks involved in making this decision to leave it up were once again taken into an executive's office.   And so we went up and there was a lot of internal pressure to remove it. And I would go to my boss and say Hey look this is the decision we made. I recognize this is controversial. I want to let you know why we made these decisions.   And they made their case.   There are valid and important human rights reasons why you would want this to be out there to show the kind of savagery. And she vehemently disagreed with that.   They took another approach arguing that if we take this down ...   You are deciding to punish people who are trying to raise awareness.   Again she was not budging.   And just did not get past that. And ultimately I was overruled and we removed it just because there was pressure to do so.   The same people that six months prior told them to leave it up because it was newsworthy said Take the video down.       If you want the one from Boston in you probably should have the one from Mexico in.   Right.   It was a mistake. Yeah I think it was a mistake. Because I felt like -- like why do we have these rules in place in the first place? And it is not the only reason but decisions like that are the thing that precipitated me leaving.   Leaving?   Yeah. Not too long after that incident a few members of the team decided to quit.   Okay. We are gonna break in here and fast forward to the present. In our original broadcast of this story Simon finished with one final story about a content moderator in the Philippines who for personal and religious reasons would ignore the rules entirely and just take down whatever she saw fit which added just one more layer of difficulty to the whole problem. But ...   I think I can hit record on my end.   Okay. I think it is working now.   Okay.   In just the past few weeks all of these questions about newsworthiness and what Facebook should or should not allow on their platform all of it has gotten even stranger and harder in ways that are definitely gonna be having an impact on the 2020 Presidential election.   Okay well so we are going -- we gotta start with President Trump.     This has sort of been all over the news.     But it is also been in the shadow of larger news events going on.   Yeah. It is like I know I have seen Facebook headlines but I honestly have not been able to absorb what is happening. So ...   Long and short of it is May 26th President Trump pens two tweets. So we are talking Twitter not Facebook here initially. Falsely claiming that mail-in ballots will lead to voter fraud and a quote rigged election.   So I mean just to be clear like there is no -- like the evidence for voter fraud is almost non-existent.   Yes. Everyone who is looked at this says this is not an issue. And so in response to these tweets Twitter decided to do something they labeled these two tweets with an exclamation point and a bit of text that read Get the facts about mail-in ballots.   The most mild fact-check one can imagine.   Yes but it is also a gargantuan step forward based on anything that they have done with Donald Trump at least up until that point. I mean it is the first time that Twitter or Facebook have fact-checked the President of the United States. Which unsurprisingly ...     He was not happy about.       And he actually went so far as to draft and sign an executive order threatening to regulate or shut down social media companies that engage in this sort of fact-checking. So you have got the left saying Twitter is not doing enough. The right is upset with Twitter for censoring conservative voices. Twitter's then in this position of like what the heck do we do next? And into that uncertainty Trump tweets the now infamous line ...     ... When the looting starts the shooting starts. This pops up at 53 p.m. And according to the reporting all of the Twitter execs got onto a virtual hang-out and just like many of the cases we just talked about at Facebook they are like What do we do about this? First thing they had to consider was that this -- this tweet did break their rules. Just like Facebook Twitter has got its own set of rules defining what does and does not constitute glorifying violence. And according to that this did glorify violence. But then at the same time this is the President of the United States. And so after going back and forth what they decide is that we are not gonna take it down because we do not want to censor the President. But what we are gonna do is we are going to shield that information and neuter this tweet's ability to spread.   Hmm. How do you -- how do you do both of those things?   So the first thing they do is if you are scrolling down your Twitter feed and you come across this tweet instead of seeing the text of that tweet all you see is This tweet has violated the Twitter rules about glorifying violence. And you then have to actually click on the tweet to view it. So there is one click that they have put between you and the information itself.   Okay. Okay.   Then let us say you want to retweet that. You want to help this information spread you want to put it in front of all of the people that follow you. You click Retweet and instead of just being able to retweet another box pops up that says Comment on this tweet. At that point you then have to write your own tweet about Donald Trump's tweet in question. And when you finally are able to tweet this the way it now shows up for others is your comment and then again that text This tweet glorifies violence.   Interesting.   So now for someone else to get to it through your feed they have to click and go through that same rigmarole.   Hmm.   So that is what Twitter decided to do. But here's where you see a real fork in the road because simultaneously ...     Trump posted the exact same thing on Facebook. And as Mark Zuckerberg explained during an interview on Fox News ...     Our policy has been for several years that we are not going to infringe upon political speech.     And so we are not gonna do anything. We are gonna let this post stand.   Hmm.   So you have got same post two different companies coming to two very different decisions.   Yeah.   And so to make sense of this difference I gave another call ...   I think that I under -- I mean I get both decisions. But I ...   To Kate Klonick.   I just would kind of be happy for some consistency.   And the way she tells it Facebook's decision to leave this post up really goes all the way back to that newsworthiness argument about the Boston Marathon bombing.   Yeah it is a little bit more complicated than that but because of newsworthiness what a public figure or someone of influence in some way posts on Facebook ...   Like say Donald Trump or Michael Jordan.   ... basically because they are a public figure it is inherently newsworthy. It is kind of a circular definition.   Essentially Facebook is saying Yes we have rules about hate speech and violence but anything a famous person says is newsworthy enough that -- so that they do not have to abide by those rules.   Wait. Does that mean that they can just say whatever the hell they want?   Pretty much.   This was one of the reasons why Donald Trump's statements ...     ... about a Muslim ban which would have come down as hate speech if anyone else had said it were kept up by the platform because they justified it as well he is like a candidate running for office a presidential candidate and this is newsworthy.   And this is where you feel the rub. Because on the one hand there is plenty of evidence that people in power using charged language can lead to violence. But on the other I think there is an argument to be made that is not it important for us to know what our leaders are saying and thinking particularly when it is threatening or dangerous. And that argument has basically exploded within Facebook's own ranks.       There is been an employee walk-out. Others have actually resigned.     And then sort of a who is who of former Facebook employees folks who were there at the beginning penned an open letter to Zuckerberg urging him to reverse his decision.   Yeah I agree that the decision is dangerous. It is that simple.   And so we actually reached back out to one of our sources from the original piece a former Facebook employee to get his take on this. Just like before we are using an actor to conceal his identity. But he says when you look at the reasoning the rationale behind this public figure newsworthiness exception ...   Yeah. In addition to it being dangerous and wrong it was just ridiculously badly done. I mean if you are gonna come up with a pretextual reason just do it more effectively. The idea that you want to protect political speech I have sympathy with but you would not do what they are doing.   Basically he is saying they are being incredibly selective in what political speech they are choosing to privilege.   You just -- you cannot stand there and say you are all in favor of free expression while banning political cartoons for hate speech. And the idea that political freedom requires that the people with the most power in society have the least rules is -- it is obvious nonsense right? The spirit of the First Amendment is meant to protect us the citizens from the powerful. Not the other way around. So I do not know. It is repugnant to me. It is like an inversion of everything it is ought to be.   Take the best parts of the internet as the amplified voices that do not traditionally have amplification on their own.     But what we are seeing in these types of rules is it doubles down on amplifying and bringing the power structures that already exist in society to the internet allowing people who are already powerful and already are newsworthy themselves even more power to speak.   And that is what makes this moment so confusing because on the one hand you have videos coming out of Black Lives Matter protests that are shining a light on issues of policing and systemic racism. And we need to see those videos. Unfiltered. But then at the same time right alongside that you have posts from the leader of the free world encouraging violence. And there they are right next to each other. Side by side. Now lastly I think it is important to keep in mind that none of this is static. That just like all their other rules and policies this public figure carve-out has been and is again being tweaked. I mean while I was tracking these very words I am saying to you now I received a notification that Facebook just removed posts from Trump's re-election campaign because those posts featured a symbol used by Nazi Germany. And not long ago Facebook actually went even further.   In light of ctually halted this exception. They said Listen if you are saying something that is false about the pandemic or about COVID-19 we are going to remove what you said no matter what.   Wow!   People were really happy with that decision. And I think that that was -- it was right where we kind of -- it was like we were pre-Boston Marathon days. And maybe where we should have been always.   This episode was reported by Simon Adler with help from Tracie Hunte and produced by Simon with help from Bethel Habte.   Big thanks to Sarah Roberts whose research into commercial content moderation got us going big time and we thank her very very much for that.   Thanks also to Jeffrey Rosen who helped us in our thinking about what Facebook is.   To Michael Chernus whose voice we used to mask other people's voices.   To Carolyn Glanville Ruchika Budhraja.   Ryan Dugan Ellen Silver James Mitchell and Guy Rosen.   And of course to all the content moderators who took the time to talk to us. And ...   Do you want to sign off?   Yeah I guess we should huh?   We should. Ready? You want to go first?   Yeah. I am Jad Abumrad.   I am Robert Krulwich.   Thanks for listening.    Copyright  2020 New York Public Radio. All rights reserved. Visit our website terms of use at www.wnyc.org for further information. New York Public Radio transcripts are created on a rush deadline often by contractors. This text may not be in its final form and may be updated or revised in the future. Accuracy and availability may vary. The authoritative record of New York Public Radios programming is the audio record.  -30- 