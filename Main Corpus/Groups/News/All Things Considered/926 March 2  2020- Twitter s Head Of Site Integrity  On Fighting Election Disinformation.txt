 Intelligence officials have warned that Russia is interfering in the 2020 presidential campaign as it did four years ago. Back then it used social media to spread disinformation and hoaxes. Yoel Roth is in charge of fighting these efforts on Twitter. He told me the company has not traced specific tweets about the 2020 campaign back to Russia but he says Russia's tactics have also evolved.  One of the main things that we saw in 2016 was the use of inauthentic personas. So these would be accounts that were pretending to be Americans to try and influence certain parts of the conversation. We have seen some indication that that remains part of the Russian playbook. And so they are trying to set up accounts that appear to be Americans or other people participating in political conversations to try and seem as though they are actually a member of the community that they are trying to impact.  And beyond candidates these might be about gun rights or Black Lives Matter or LGBT rights or anything else that was controversial. At least that is what was documented in the Mueller report.  Right. Those were some of the tactics that we saw most clearly in 2016 but I would note that some of the tactics have evolved a little bit since then. For instance in 2018 we saw activity that we believe to have been connected with the Russian Internet Research Agency that was specifically targeting journalists in an attempt to convince them that there had been large-scale activity on the platform that did not actually happen.  Oh so you are saying that in 2018 Russia did not just interfere in the election. They tried to make it look like there was more interference in the election than there was just to undermine confidence.  That is right. So on election night 2018 a website went up that was called IRAUSA. So it explicitly indicated that it was the Internet Research Agency in the United States.  And that is the so-called troll farm operated out of St. Petersburg Russia.  Yes. And this website's claim was a very simple one. They said we have been setting up thousands of accounts and we were interfering in the 2018 midterms the way that we interfered in 2016.  So that is what was new in 2018. I know it is early days still but what is your best sense of what is new in 2020?  I think in 2020 we are facing a particularly divisive political moment here in the United States and attempts to capitalize on those divisions amongst Americans seem to be where malicious actors are headed. This is a similar pattern to what we saw in 2016 and 2018 but one of the things that we have seen from not only Russia but a wide range of malicious actors is an attempt to capitalize on some of the major domestic voices that are participating in these conversations and then double down on some of those activities.  And you are saying they do not have to create their own original messaging. They can just amplify some of the most extreme messaging that is coming out from real-life authentic Americans.  That is right.  I want to ask you about a slightly different topic. The distortion of reality in the election is not just coming from foreign actors. American political campaigns are also trying to use social media to their advantage. What are you seeing from 2020 candidates that raises flags for you?  We have seen everything ranging from accounts that are pretending to be compromised - so they will sort of pretend that they were hacked and then share content that they might otherwise not have but it was actually a real person - to sort of large-scale attempts to mobilize volunteers to share content on the service.  I understand you have suspended dozens of pro-Bloomberg accounts for platform manipulation. These are real people that the campaign paid to promote the candidate. How do you know that you are not overreaching and suspending accounts of Americans who are expressing their real beliefs?  The first thing I would emphasize is that we do not know whether these accounts were in fact operated by the campaign or not. Our focus whenever we are enforcing our policies is to look at the behavior that the accounts are engaged in not who we think is behind them or what their motivations were because in most instances we do not know. And so we enforced our policies against a number of accounts that were engaged in spam. These were accounts that were all tweeting the same thing at the same time. And so behaviorally we were able to clearly identify that those accounts were in violation of our rules.  Are you saying that if I text all of my supporters and say please tweet Ari will make my life better and a thousand people tweet Ari will make my life better that would be spamming even though those are real people who might actually believe I will make their life better?  No. The behavior that you described - a lot of people getting together and organizing and mobilizing around a topic and sharing information about it - is not by itself spam. But if each one of your supporters were to set up 10 different accounts just for the purpose of tweeting about how much they like you that is something that would cross the line on some of our policies around coordinated manipulation. And so the action that you saw around some of these campaign accounts was really that a single individual was operating multiple accounts with the intent of disseminating these messages. Individual people who are participating in a conversation in an organic way are of course free to use the service to advocate on behalf of whomever or whatever they choose. You just cannot do it in a way that crosses the lines of coordinated manipulation and spam.  Yoel Roth is Twitter's head of site integrity. Thank you for the conversation.  Thank you.  And tomorrow we will hear about Twitter's new policy to flag misleading content. 